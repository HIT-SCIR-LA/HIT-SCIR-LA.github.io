@inproceedings{wang-etal-2022-adaptive,
 abstract = {Supervised methods have achieved remarkable results in disfluency detection. However, in real-world scenarios, human-annotated data is difficult to obtain. Recent works try to handle disfluency detection with unsupervised self-training, which can exploit existing large-scale unlabeled data efficiently. However, their self-training-based methods suffer from the problems of selection bias and error accumulation. To tackle these problems, we propose an adaptive unsupervised self-training method for disfluency detection. Specifically, we re-weight the importance of each training example according to its grammatical feature and prediction confidence. Experiments on the Switchboard dataset show that our method improves 2.3 points over the current SOTA unsupervised method. Moreover, our method is competitive with the SOTA supervised method.},
 address = {Gyeongju, Republic of Korea},
 author = {Wang, Zhongyuan  and
Wang, Yixuan  and
Wang, Shaolei  and
Che, Wanxiang},
 booktitle = {Proceedings of the 29th International Conference on Computational Linguistics},
 month = {October},
 pages = {7209--7218},
 publisher = {International Committee on Computational Linguistics},
 title = {Adaptive Unsupervised Self-training for Disfluency Detection},
 url = {https://aclanthology.org/2022.coling-1.632},
 year = {2022}
}
