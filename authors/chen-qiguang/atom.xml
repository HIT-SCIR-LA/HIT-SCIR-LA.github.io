<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title> - Chen Qiguang</title>
    <link rel="self" type="application/atom+xml" href="/authors/chen-qiguang/atom.xml"/>
    <link rel="alternate" type="text/html" href="/"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2025-01-01T00:00:00+00:00</updated>
    <id>/authors/chen-qiguang/atom.xml</id>
    <entry xml:lang="en">
        <title>A survey of multilingual large language models</title>
        <published>2025-01-01T00:00:00+00:00</published>
        <updated>2025-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2025-a-survey-of-multilingual-large-language-models/"/>
        <id>/publications/2025-a-survey-of-multilingual-large-language-models/</id>
        
        <content type="html" xml:base="/publications/2025-a-survey-of-multilingual-large-language-models/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>Aware First Think Less Dynamic Boundary Self-Awareness Drives Extreme Reasoning Efficiency in Large Language Models</title>
        <published>2025-01-01T00:00:00+00:00</published>
        <updated>2025-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2025-aware-first-think-less-dynamic-boundary-self-awareness-drives-extreme-reasoning-efficiency-in-large-language-models/"/>
        <id>/publications/2025-aware-first-think-less-dynamic-boundary-self-awareness-drives-extreme-reasoning-efficiency-in-large-language-models/</id>
        
        <content type="html" xml:base="/publications/2025-aware-first-think-less-dynamic-boundary-self-awareness-drives-extreme-reasoning-efficiency-in-large-language-models/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>Can Large Language Models Understand You Better An MBTI Personality Detection Dataset Aligned with Population Traits</title>
        <published>2025-01-01T00:00:00+00:00</published>
        <updated>2025-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2025-can-large-language-models-understand-you-better-an-mbti-personality-detection-dataset-aligned-with-population-traits/"/>
        <id>/publications/2025-can-large-language-models-understand-you-better-an-mbti-personality-detection-dataset-aligned-with-population-traits/</id>
        
        <content type="html" xml:base="/publications/2025-can-large-language-models-understand-you-better-an-mbti-personality-detection-dataset-aligned-with-population-traits/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>DLPO Towards a Robust Efficient and Generalizable Prompt Optimization Framework from a Deep-Learning Perspective</title>
        <published>2025-01-01T00:00:00+00:00</published>
        <updated>2025-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2025-dlpo-towards-a-robust-efficient-and-generalizable-prompt-optimization-framework-from-a-deep-learning-perspective/"/>
        <id>/publications/2025-dlpo-towards-a-robust-efficient-and-generalizable-prompt-optimization-framework-from-a-deep-learning-perspective/</id>
        
        <content type="html" xml:base="/publications/2025-dlpo-towards-a-robust-efficient-and-generalizable-prompt-optimization-framework-from-a-deep-learning-perspective/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>Towards reasoning era A survey of long chain-of-thought for reasoning large language models</title>
        <published>2025-01-01T00:00:00+00:00</published>
        <updated>2025-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2025-towards-reasoning-era-a-survey-of-long-chain-of-thought-for-reasoning-large-language-models/"/>
        <id>/publications/2025-towards-reasoning-era-a-survey-of-long-chain-of-thought-for-reasoning-large-language-models/</id>
        
        <content type="html" xml:base="/publications/2025-towards-reasoning-era-a-survey-of-long-chain-of-thought-for-reasoning-large-language-models/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>Visual thoughts A unified perspective of understanding multimodal chain-of-thought</title>
        <published>2025-01-01T00:00:00+00:00</published>
        <updated>2025-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2025-visual-thoughts-a-unified-perspective-of-understanding-multimodal-chain-of-thought/"/>
        <id>/publications/2025-visual-thoughts-a-unified-perspective-of-understanding-multimodal-chain-of-thought/</id>
        
        <content type="html" xml:base="/publications/2025-visual-thoughts-a-unified-perspective-of-understanding-multimodal-chain-of-thought/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>CoMT A Novel Benchmark for Chain of Multi-modal Thought on Large Vision-Language Models</title>
        <published>2024-01-01T00:00:00+00:00</published>
        <updated>2024-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2024-comt-a-novel-benchmark-for-chain-of-multi-modal-thought-on-large-vision-language-models/"/>
        <id>/publications/2024-comt-a-novel-benchmark-for-chain-of-multi-modal-thought-on-large-vision-language-models/</id>
        
        <content type="html" xml:base="/publications/2024-comt-a-novel-benchmark-for-chain-of-multi-modal-thought-on-large-vision-language-models/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>Decoupling breaks data barriers a decoupled pre-training framework for multi-intent spoken language understanding</title>
        <published>2024-01-01T00:00:00+00:00</published>
        <updated>2024-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2024-decoupling-breaks-data-barriers-a-decoupled-pre-training-framework-for-multi-intent-spoken-language-understanding/"/>
        <id>/publications/2024-decoupling-breaks-data-barriers-a-decoupled-pre-training-framework-for-multi-intent-spoken-language-understanding/</id>
        
        <content type="html" xml:base="/publications/2024-decoupling-breaks-data-barriers-a-decoupled-pre-training-framework-for-multi-intent-spoken-language-understanding/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>M3CoT A Novel Benchmark for Multi-Domain Multi-step Multi-modal Chain-of-Thought</title>
        <published>2024-01-01T00:00:00+00:00</published>
        <updated>2024-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2024-m3cot-a-novel-benchmark-for-multi-domain-multi-step-multi-modal-chain-of-thought/"/>
        <id>/publications/2024-m3cot-a-novel-benchmark-for-multi-domain-multi-step-multi-modal-chain-of-thought/</id>
        
        <content type="html" xml:base="/publications/2024-m3cot-a-novel-benchmark-for-multi-domain-multi-step-multi-modal-chain-of-thought/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>Unlocking the Capabilities of Thought A Reasoning Boundary Framework to Quantify and Optimize Chain-of-Thought</title>
        <published>2024-01-01T00:00:00+00:00</published>
        <updated>2024-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2024-unlocking-the-capabilities-of-thought-a-reasoning-boundary-framework-to-quantify-and-optimize-chain-of-thought/"/>
        <id>/publications/2024-unlocking-the-capabilities-of-thought-a-reasoning-boundary-framework-to-quantify-and-optimize-chain-of-thought/</id>
        
        <content type="html" xml:base="/publications/2024-unlocking-the-capabilities-of-thought-a-reasoning-boundary-framework-to-quantify-and-optimize-chain-of-thought/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>What Factors Affect Multi-Modal In-Context Learning An In-Depth Exploration</title>
        <published>2024-01-01T00:00:00+00:00</published>
        <updated>2024-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2024-what-factors-affect-multi-modal-in-context-learning-an-in-depth-exploration/"/>
        <id>/publications/2024-what-factors-affect-multi-modal-in-context-learning-an-in-depth-exploration/</id>
        
        <content type="html" xml:base="/publications/2024-what-factors-affect-multi-modal-in-context-learning-an-in-depth-exploration/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>Cross-lingual Prompting Improving Zero-shot Chain-of-Thought Reasoning across Languages</title>
        <published>2023-01-01T00:00:00+00:00</published>
        <updated>2023-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2023-cross-lingual-prompting-improving-zero-shot-chain-of-thought-reasoning-across-languages/"/>
        <id>/publications/2023-cross-lingual-prompting-improving-zero-shot-chain-of-thought-reasoning-across-languages/</id>
        
        <content type="html" xml:base="/publications/2023-cross-lingual-prompting-improving-zero-shot-chain-of-thought-reasoning-across-languages/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>CGIM A Cycle Guided Interactive Learning Model for Consistency Identification in Task-oriented Dialogue</title>
        <published>2022-01-01T00:00:00+00:00</published>
        <updated>2022-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2022-cgim-a-cycle-guided-interactive-learning-model-for-consistency-identification-in-task-oriented-dialogue/"/>
        <id>/publications/2022-cgim-a-cycle-guided-interactive-learning-model-for-consistency-identification-in-task-oriented-dialogue/</id>
        
        <content type="html" xml:base="/publications/2022-cgim-a-cycle-guided-interactive-learning-model-for-consistency-identification-in-task-oriented-dialogue/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>GL-CLeF A Global-Local Contrastive Learning Framework for Cross-lingual Spoken Language Understanding</title>
        <published>2022-01-01T00:00:00+00:00</published>
        <updated>2022-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2022-gl-clef-a-global-local-contrastive-learning-framework-for-cross-lingual-spoken-language-understanding/"/>
        <id>/publications/2022-gl-clef-a-global-local-contrastive-learning-framework-for-cross-lingual-spoken-language-understanding/</id>
        
        <content type="html" xml:base="/publications/2022-gl-clef-a-global-local-contrastive-learning-framework-for-cross-lingual-spoken-language-understanding/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>Dont be Contradicted with Anything CI-ToD Towards Benchmarking Consistency for Task-oriented Dialogue System</title>
        <published>2021-01-01T00:00:00+00:00</published>
        <updated>2021-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2021-dont-be-contradicted-with-anything-ci-tod-towards-benchmarking-consistency-for-task-oriented-dialogue-system/"/>
        <id>/publications/2021-dont-be-contradicted-with-anything-ci-tod-towards-benchmarking-consistency-for-task-oriented-dialogue-system/</id>
        
        <content type="html" xml:base="/publications/2021-dont-be-contradicted-with-anything-ci-tod-towards-benchmarking-consistency-for-task-oriented-dialogue-system/"></content>
        
    </entry>
</feed>
