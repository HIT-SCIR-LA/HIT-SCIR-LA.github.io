<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
	<title> - Yang Ziqing</title>
	<link href="/authors/yang-ziqing/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="/"/>
	<generator uri="https://www.getzola.org/">Zola</generator>
	<updated>2021-01-01T00:00:00+00:00</updated>
	<id>/authors/yang-ziqing/atom.xml</id>
	<entry xml:lang="en">
		<title>Adversarial Training for Machine Reading Comprehension with Virtual Embeddings</title>
		<published>2021-01-01T00:00:00+00:00</published>
		<updated>2021-01-01T00:00:00+00:00</updated>
		<link rel="alternate" href="/publications/2021-adversarial-training-for-machine-reading-comprehension-with-virtual-embeddings/" type="text/html"/>
		<id>/publications/2021-adversarial-training-for-machine-reading-comprehension-with-virtual-embeddings/</id>
		<content type="html"></content>
	</entry>
	<entry xml:lang="en">
		<title>Bilingual Alignment Pre-Training for Zero-Shot Cross-Lingual Transfer</title>
		<published>2021-01-01T00:00:00+00:00</published>
		<updated>2021-01-01T00:00:00+00:00</updated>
		<link rel="alternate" href="/publications/2021-bilingual-alignment-pre-training-for-zero-shot-cross-lingual-transfer/" type="text/html"/>
		<id>/publications/2021-bilingual-alignment-pre-training-for-zero-shot-cross-lingual-transfer/</id>
		<content type="html"></content>
	</entry>
	<entry xml:lang="en">
		<title>A Sentence Cloze Dataset for Chinese Machine Reading Comprehension</title>
		<published>2020-01-01T00:00:00+00:00</published>
		<updated>2020-01-01T00:00:00+00:00</updated>
		<link rel="alternate" href="/publications/2020-a-sentence-cloze-dataset-for-chinese-machine-reading-comprehension/" type="text/html"/>
		<id>/publications/2020-a-sentence-cloze-dataset-for-chinese-machine-reading-comprehension/</id>
		<content type="html"></content>
	</entry>
	<entry xml:lang="en">
		<title>TextBrewer An Open-Source Knowledge Distillation Toolkit for Natural Language Processing</title>
		<published>2020-01-01T00:00:00+00:00</published>
		<updated>2020-01-01T00:00:00+00:00</updated>
		<link rel="alternate" href="/publications/2020-textbrewer-an-open-source-knowledge-distillation-toolkit-for-natural-language-processing/" type="text/html"/>
		<id>/publications/2020-textbrewer-an-open-source-knowledge-distillation-toolkit-for-natural-language-processing/</id>
		<content type="html"></content>
	</entry>
	<entry xml:lang="en">
		<title>Improving machine reading comprehension via adversarial training</title>
		<published>2019-01-01T00:00:00+00:00</published>
		<updated>2019-01-01T00:00:00+00:00</updated>
		<link rel="alternate" href="/publications/2019-improving-machine-reading-comprehension-via-adversarial-training/" type="text/html"/>
		<id>/publications/2019-improving-machine-reading-comprehension-via-adversarial-training/</id>
		<content type="html"></content>
	</entry>
	<entry xml:lang="en">
		<title>Pre-training with whole word masking for chinese bert</title>
		<published>2019-01-01T00:00:00+00:00</published>
		<updated>2019-01-01T00:00:00+00:00</updated>
		<link rel="alternate" href="/publications/2019-pre-training-with-whole-word-masking-for-chinese-bert/" type="text/html"/>
		<id>/publications/2019-pre-training-with-whole-word-masking-for-chinese-bert/</id>
		<content type="html"></content>
	</entry>
	<entry xml:lang="en">
		<title>Interactive Gated Decoder for Machine Reading Comprehension</title>
		<published>2010-01-01T00:00:00+00:00</published>
		<updated>2010-01-01T00:00:00+00:00</updated>
		<link rel="alternate" href="/publications/2010-interactive-gated-decoder-for-machine-reading-comprehension/" type="text/html"/>
		<id>/publications/2010-interactive-gated-decoder-for-machine-reading-comprehension/</id>
		<content type="html"></content>
	</entry>
</feed>
