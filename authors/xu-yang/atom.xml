<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title> - Xu Yang</title>
    <link rel="self" type="application/atom+xml" href="/authors/xu-yang/atom.xml"/>
    <link rel="alternate" type="text/html" href="/"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2025-01-01T00:00:00+00:00</updated>
    <id>/authors/xu-yang/atom.xml</id>
    <entry xml:lang="en">
        <title>Can Large Language Models Understand You Better An MBTI Personality Detection Dataset Aligned with Population Traits</title>
        <published>2025-01-01T00:00:00+00:00</published>
        <updated>2025-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2025-can-large-language-models-understand-you-better-an-mbti-personality-detection-dataset-aligned-with-population-traits/"/>
        <id>/publications/2025-can-large-language-models-understand-you-better-an-mbti-personality-detection-dataset-aligned-with-population-traits/</id>
        
        <content type="html" xml:base="/publications/2025-can-large-language-models-understand-you-better-an-mbti-personality-detection-dataset-aligned-with-population-traits/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>Judge Q Trainable Queries for Optimized Information Retention in KV Cache Eviction</title>
        <published>2025-01-01T00:00:00+00:00</published>
        <updated>2025-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2025-judge-q-trainable-queries-for-optimized-information-retention-in-kv-cache-eviction/"/>
        <id>/publications/2025-judge-q-trainable-queries-for-optimized-information-retention-in-kv-cache-eviction/</id>
        
        <content type="html" xml:base="/publications/2025-judge-q-trainable-queries-for-optimized-information-retention-in-kv-cache-eviction/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>Lookahead Q-Cache Achieving More Consistent KV Cache Eviction via Pseudo Query</title>
        <published>2025-01-01T00:00:00+00:00</published>
        <updated>2025-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2025-lookahead-q-cache-achieving-more-consistent-kv-cache-eviction-via-pseudo-query/"/>
        <id>/publications/2025-lookahead-q-cache-achieving-more-consistent-kv-cache-eviction-via-pseudo-query/</id>
        
        <content type="html" xml:base="/publications/2025-lookahead-q-cache-achieving-more-consistent-kv-cache-eviction-via-pseudo-query/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>Beyond Static Evaluation A Dynamic Approach to Assessing AI Assistants API Invocation Capabilities</title>
        <published>2024-01-01T00:00:00+00:00</published>
        <updated>2024-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2024-beyond-static-evaluation-a-dynamic-approach-to-assessing-ai-assistants-api-invocation-capabilities/"/>
        <id>/publications/2024-beyond-static-evaluation-a-dynamic-approach-to-assessing-ai-assistants-api-invocation-capabilities/</id>
        
        <content type="html" xml:base="/publications/2024-beyond-static-evaluation-a-dynamic-approach-to-assessing-ai-assistants-api-invocation-capabilities/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>Concise and Precise Context Compression for Tool-Using Language Models</title>
        <published>2024-01-01T00:00:00+00:00</published>
        <updated>2024-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2024-concise-and-precise-context-compression-for-tool-using-language-models/"/>
        <id>/publications/2024-concise-and-precise-context-compression-for-tool-using-language-models/</id>
        
        <content type="html" xml:base="/publications/2024-concise-and-precise-context-compression-for-tool-using-language-models/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>Self-Constructed Context Decompilation with Fined-grained Alignment Enhancement</title>
        <published>2024-01-01T00:00:00+00:00</published>
        <updated>2024-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2024-self-constructed-context-decompilation-with-fined-grained-alignment-enhancement/"/>
        <id>/publications/2024-self-constructed-context-decompilation-with-fined-grained-alignment-enhancement/</id>
        
        <content type="html" xml:base="/publications/2024-self-constructed-context-decompilation-with-fined-grained-alignment-enhancement/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>LayoutLMv2 Multi-modal Pre-training for Visually-rich Document Understanding</title>
        <published>2021-01-01T00:00:00+00:00</published>
        <updated>2021-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2021-layoutlmv2-multi-modal-pre-training-for-visually-rich-document-understanding/"/>
        <id>/publications/2021-layoutlmv2-multi-modal-pre-training-for-visually-rich-document-understanding/</id>
        
        <content type="html" xml:base="/publications/2021-layoutlmv2-multi-modal-pre-training-for-visually-rich-document-understanding/"></content>
        
    </entry>
    <entry xml:lang="en">
        <title>HIT-SCIR at MRP 2019 A Unified Pipeline for Meaning Representation Parsing via Efficient Training and Effective Encoding</title>
        <published>2019-01-01T00:00:00+00:00</published>
        <updated>2019-01-01T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="/publications/2019-hit-scir-at-mrp-2019-a-unified-pipeline-for-meaning-representation-parsing-via-efficient-training-and-effective-encoding/"/>
        <id>/publications/2019-hit-scir-at-mrp-2019-a-unified-pipeline-for-meaning-representation-parsing-via-efficient-training-and-effective-encoding/</id>
        
        <content type="html" xml:base="/publications/2019-hit-scir-at-mrp-2019-a-unified-pipeline-for-meaning-representation-parsing-via-efficient-training-and-effective-encoding/"></content>
        
    </entry>
</feed>
